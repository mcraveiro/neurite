#+title: Nerd Food: Tooling in Computational Neuroscience - Part II: SWC
#+options: date:nil toc:nil author:nil num:nil title:nil

#+begin_html
<p class="verse" style="text-align:right">
<small>
Research is what I'm doing when I don't know what I'm doing.
<br>
<i>Wernher von Braun</i>
</small>
</p>
#+end_html

Welcome to the second instalment of our second series on Computational
Neuroscience for lay people. You can find the first post of the
previous series [[http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks.html][here]], and the first post of the second series [[http://mcraveiro.blogspot.co.uk/2015/11/nerd-food-tooling-in-computational.html][here]]. As
you'd expect, this second series is slightly more advanced, and it is
peppered with the unavoidable bits of technical jargon. Having said
that, we shall continue to pursue our ambitious target of making
things as easy to parse as possible (but no easier). If you read the
first series, the second should hopefully make some kind of
sense.[fn:feynman]

In the [[http://mcraveiro.blogspot.co.uk/2015/11/nerd-food-tooling-in-computational.html][previous post]] we discussed [[https://en.wikipedia.org/wiki/Computational_neuroscience][Computational Neuroscience]] as a
discipline, and the kind of things one may want to do in this
field. We also spoke about models and their composition, and the
desirable properties of a platform that runs simulations of said
models. However, it occurred to me that we should probably build some
kind of "end-to-end" understanding; that is, by starting with the
simulations and models we are missing a vital link with the physical
(e.g. non-computational) world. To put matters right, this part
attempts to provide a high-level introduction on how data is acquired
from the real world and then used - amongst other things - to inform
the modeling process. The part ends with a quick tour of the venerable
SWC format, which still plays an important role in representing 3D
neuron morphologies.

* In The Beginning There Was the Microscope

For purposes of this post, the data gathering process starts with the
microscope. Of course, keep in mind that we are focusing only on the
/morphology/ at present - the shape and the structures that make up
the neuron - so we are ignoring other important activities in the
lab. For instance, one can conduct experiments to measure voltage in
neurons and these measurements provide data for the functional aspects
of the models. Alas, we will skip these for now, with the promise of
returning to them at a later date[fn:neuroimaging].

So, microscopes then. [[https://en.wikipedia.org/wiki/Microscopy][Microscopy]] is the technical name for the
observation work done with the microscope. Because neurons are so
small - some 4 to 100 microns in size - only certain types of
microscopes are suitable to perform neuronal microscopy. To make
matters worse, the sub-structures inside the neuron are really what we
want to know about and these can be ridiculously small. For example, a
[[https://en.wikipedia.org/wiki/Dendritic_spine][dentritic spine]] - the minute protrusions that come out of the
dendrites - can be as tiny as 500 nanometres; the lipid bylayer itself
is only 2 or 3 nanometres thick, so you can imagine how incredibly
small ion channels and pumps must be. Yet these are the things we want
to observe and measure.

#+CAPTION: Example of measurements one may want to perform on a dendrite. Source: [[http://www.pnas.org/content/106/39/16877.abstract][Reversal of long-term dendritic spine alterations in Alzheimer disease models]]
#+attr_html: :width 300px :height 300px
http://www.pnas.org/content/106/39/16877/F1.large.jpg

Given these demands, there are only a few extremely specialised - and
/extremely/ expensive - tools for the job. The main tool of choice is
the [[https://en.wikipedia.org/wiki/Electron_microscope][Electron Microscope (EM)]]. This crazy critter can provide insane
levels of magnification by using a beam of electrons instead of
visible light, as done by the more conventional [[https://en.wikipedia.org/wiki/Optical_microscope][Optical
Microscopes]]. In particular, the [[https://en.wikipedia.org/wiki/Scanning_electron_microscope][Scanning Electron Microscope]] (SEM)
performs a scan of the object under study, and has a resolution higher
than 1 nanometre. There are also [[https://en.wikipedia.org/wiki/Confocal_microscopy][Confocal Microscopes]] which use a
technique patented by [[https://en.wikipedia.org/wiki/Marvin_Minsky][Marvin Minsky]] - yes, he of Computer Science and
AI fame - that improves resolution and contrast. It seems the same
principles can be applied to EM as well, creating [[https://en.wikipedia.org/wiki/Scanning_confocal_electron_microscopy][SCEM
microscopes]][fn:microscopes]. And, as we shall see, the variety of
microscopy approaches does not end there either.

At any rate, whatever the technical details, the fact is that the
imagery that results from all of these advances is truly
haunting. Take this image:

#+CAPTION: Human neuron. [[http://ucsdnews.ucsd.edu/pressrelease/new_reprogramming_method_makes_better_stem_cells][Source: New Reprogramming Method Makes Better Stem Cells]]
#+attr_html: :width 300px :height 300px
http://ucsdnews.ucsd.edu/news_uploads/2014_06_26_human_ipsc_derived_neuron_deerinck.jpg

Technically, these pictures are called [[https://en.wikipedia.org/wiki/Micrograph][micrographs]]. As you can see,
micrographs provide a great visual description of the topology of the
object we are trying to study. You also may notice a slight coloration of
the cell in that picture. This is most likely due to the fact that the
people doing the analysis [[https://en.wikipedia.org/wiki/Staining][stain]] the neuron to make it easier to
image. Its worth noting that the entire process, including staining
and creating the micrographs, is still highly manual and requires a
lot of skill, most likely done by an expert human neuroanatomist.

Now, in practice - at least as far as I have seen, which is not very
far at all, to be fair - 2D grayscale images are preferred by
researchers to the nice, Public Relations friendly pictures like the
one above; those appear to be more useful for magazine covers. The
working micrographs are not quite as exciting to the untrained eye but
very useful to the professionals. Here's an example:

#+CAPTION: The left-hand side shows the original micrograph. On the right-hand side it shows the result of processing it with machine learning. Source: [[http://papers.nips.cc/paper/4741-deep-neural-networks-segment-neuronal-membranes-in-electron-microscopy-images.pdf][Deep Neural Networks Segment Neuronal Membranes in Electron Microscopy Images]]
#+attr_html: :width 600px :height 200px
http://www.leet.it/home/giusti/website/lib/exe/fetch.php?w=900&tok=d88a10&media=wiki:biomed-neurons.jpg

Let's focus on the left-hand side of this image for a moment. It was
taken using /ssTEM/ - serial-section Transmitted Electron Microscopy -
a recent evolutionary step in the [[https://en.wikipedia.org/wiki/Transmission_electron_microscopy][Transmission Electron Microscopy]]
(TEM). Now, We don't want to stray /too/ far adrift, but its probably
worth mentioning a word or two on TEM. It is a technology that has
been used by neuroscientists for a very long time; in the fifties it
was used to show that neurons communicate over synaptic
junctions. Anyhow, the /ss/ part of ssTEM is helpful in creating
/stacks/ of images, which is why you see the cool drawings next to the
picture; they are there to give you the idea that the top-most image
is one of 30 in a stack.

The process of producing the images above was as follows: they started
off with a neuronal tissue sample, which is prepared for
observation. The sample had 1.5 micrometres and was then sectioned
into 30 slices of 50 nanometres. Each of these slices was imaged, at a
resolution of 4x4 nanometres per pixel.

As you can imagine, this work is extremely sensitive to measurement
error. The trick is to ensure there is some kind of visual continuity
between images so that you can recreate a 3D model from the 2D
slices. This means for instance that if you are trying to figure out
connectivity, you need some way to relate a dendrite to it's soma and
say to the axon of the neuron it connects to - and that's why the
slices have to be so thin. It would be no good if the pictures miss
this information out as you will not be able to recreate the
connectivity faithfully. This is actually really difficult to achieve
in practice due to the minute sizes involved; a slight tremor that
displaces the sample by some nanometres would cause shifts in
aligment. In addition, in the real world these samples are not
sliced - the sizes are too small for that now - but instead, thin
layers from the sample are /burnt/ away and then the sample is
re-imagined. Even with the high-precision the tools have, you can
imagine that there is always some kind of movement in the sample's
position.

Its also worth noticing that, even though the images are 2D grayscale,
since the pixel size is only a few nanometres wide (say 4x4), the full
size of an image is very large. Indeed, the latest generation of
microscopes produce stacks on the 500 Terabyte range, making the
processing of the images a "big-data" challenge.

Images in a stack are normally stored using traditional formats such
as [[https://en.wikipedia.org/wiki/Tagged_Image_File_Format][TIFF]]. You can see an example of the raw images in a stack [[https://github.com/unidesigner/groundtruth-drosophila-vnc/tree/master/stack2/raw][here]]. On
the topic of formats: its probably time we mention the [[https://www.openmicroscopy.org/site][Open Microscopy
Environment]] (OME). The microscopy world is dominated by hardware and
as such its the perfect environment for corporations, their
proprietary formats and expensive software packages. The OME guys are
trying to buck the trend by creating a suite of open source tools and
protocols, and by looking at some of [[http://help.openmicroscopy.org/viewing-data.html#screen][their stuff]], they seem to be
doing alright.

* What To Do Once You Got the Images

But back to the task at hand. Once you have micrographs, the next
logical step is to try to figure out what's what: which objects are in
the picture. This is called segmentation and labelling, presumably
because you are breaking the one big monolithic picture into discrete
objects and giving them names. Historically, segmentation has been
done manually, but its a painful, slow and error-prone process. Due to
this, there is a lot of interest in automation, and it has recently
become feasible to do so - what with the abundance of cheap computing
resources as well as the advent of "useful" [[https://en.wikipedia.org/wiki/Machine_learning][machine learning]] (rather
than the theoretical variety). Cracking this puzzle is gaining
popularity amongst the programming nerds as you can see by the
popularity of challenges such as this one: [[http://fiji.sc/Segmentation_of_neuronal_structures_in_EM_stacks_challenge_-_ISBI_2012][Segmentation of neuronal
structures in EM stacks challenge - ISBI 2012]]. It is from this
challenge we sourced the stack and micrograph above. There are also
open source packages to help with segmentation. A couple of notable
contenders are [[http://fiji.sc/Fiji][Fiji]] and [[http://ilastik.org/][Ilastik]].

#+CAPTION: Source: [[http://ilastik.org/gallery.html#][Ilastik gallery]].
#+attr_html: :width 300px :height 300px
https://raw.githubusercontent.com/ilastik/ilastik.github.io/master/gallery/Figure-2-a.png

Three-Dimensional Immersive Virtual Reality forStudying Cellular
Compartments in 3D ModelsFrom EM Preparations of Neural Tissues
http://onlinelibrary.wiley.com/doi/10.1002/cne.23852/epdf


An activity that naturally follows on from segmentation and labelling
is [[https://en.wikipedia.org/wiki/Neuronal_tracing][reconstruction]]. The objective of reconstruction is to try to
reconstruct morphology given the images in the stack. It could involve
inferring the missing bits of information or any other kind of
analysis which transforms the set of discrete objects spotted by
segmentation into something looking more like a bunch of connected
neurons.

Once we have a reconstructed model, we can start performing
/morphometric analysis/. As wikipedia tells us, [[https://en.wikipedia.org/wiki/Morphometrics][Morphometry]] is "the
quantitative analysis of form"; as you can imagine, there are a lot of
useful things one may want to measure in the brain structures and
sub-structures such as lengths, volumes, surface area and so on. Some
of these measurements can of course be done in 2D, but life is made
easier if the model is available in 3D.

One such tool is [[http://wiki.blender.org/index.php/Extensions:2.6/Py/Scripts/Neuro_tool][NeuroMorph]]. It is an open source extension written in
Python for the popular open source 3D computer graphics software
[[https://en.wikipedia.org/wiki/Blender_(software)][Blender]].



#+CAPTION: Source: [[http://figshare.com/articles/Segmented_anisotropic_ssTEM_dataset_of_neural_tissue/856713][Segmented anisotropic ssTEM dataset of neural tissue]]
#+attr_html: :width 300px :height 300px
http://wiki.blender.org/uploads/9/98/NeuroMorph_screenshot.png

in an ideal
world one would want to export the stack, its associated segmentation
and labelling meta-data into a tool that can create three-dimensional
structures for morphometric analysis.

Unfortunately for the lovers of Free Software, reconstruction
tends to be done using proprietary tools such as [[http://www.mbfbioscience.com/neurolucida][NeuroLucida]]. On the
plus side, NeuroLucida does output slightly more open formats such as
NeuroLucida XML, which appears to have been [[https://code.google.com/p/ontomorphtab/source/browse/trunk/OntoMorph2/etc/neurolucida-xml/neurolucida-xml.xsd?r%3D335][reverse-engineered]].

* Stuff

Segmentation and Tracking of 3D Neuron Microscopy Images Using a
PDE Based Method and Connected Component Labeling algorithm
ftp://ftp.math.ucla.edu/pub/camreport/cam08-03.pdf

http://previews.figshare.com/1288336/preview_1288336.jpg
http://web.cs.ucla.edu/~dt/papers/tmi94/tmi94.pdf

[fn:feynman] As a bit of an aside, I was totally unaware of the
[[https://www.farnamstreetblog.com/2012/04/learn-anything-faster-with-the-feynman-technique/][Feynman Technique]], but after reading that post I became convinced I
have been trying to apply it all along. On this topic (and the reason
why I came to know of the Feynman Technique), read [[https://www.farnamstreetblog.com/2015/01/richard-feynman-knowing-something/][Richard Feynman:
The Difference Between Knowing the Name of Something and Knowing
Something]].

[fn:neuroimaging] Nor is the microscope the only way to figure out
what is happening inside the brain. For example, there are
[[https://en.wikipedia.org/wiki/Neuroimaging][neuroimagining]] techniques which can provide data about both structure
and function.

[fn:microscopes] And of course, progress stands still for no one, so
there are many new developments in this area. [[http://blogs.scientificamerican.com/expeditions/journey-through-the-brain-multiphoton-microscopy/][Multiphoton Microscopy]],
for one, seems extremely interesting.
