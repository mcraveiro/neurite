#+title: Nerd Food: Tooling in Computational Neuroscience - Part II: SWC
#+options: date:nil toc:nil author:nil num:nil title:nil

Welcome to the next instalment of our second series on Computational
Neuroscience, for lay people. You can find the first post of the
previous series [[http://mcraveiro.blogspot.co.uk/2015/08/nerd-food-neurons-for-computer-geeks.html][here]]. This second series is slightly more advanced and
talks about the tools of the trade, but if you read the first one it
should make some sense.

In the [[http://mcraveiro.blogspot.co.uk/2015/11/nerd-food-tooling-in-computational.html][previous post]] of this series we discussed [[https://en.wikipedia.org/wiki/Computational_neuroscience][Computational
Neuroscience]] as a discipline, and the kind of things one may want to
do in this field. We also spoke about models and their composition,
and the kind properties one may want of a simulation platform in order
to run simulations of these models. However, it occurred to me that it
is useful to have some kind of "end-to-end" understanding. That is, by
starting with the simulations and models we are missing a vital link
with the physical (e.g. non-computational) world. To put matters
right, this part attempts to provide a high-level introduction of how
the data acquired from the real world is and then used to inform the
models. We end the part by covering the SWC format, which plays an
important role in representing 3D neuron morphologies.

* In The Beginning There Was the Microscope

For our purposes, the data gathering process starts with the
microscope. Of course, you have to keep in mind that we are focusing
only on the /morphology/ at present~--- that is, the structures that
make up the neuron~--- so we are ignoring the experimental part. For
instance, one can conduct experiments to measure voltage in neurons
and so on and these measurements will then inform the functional
aspects of the models. But we will ignore these for now and perhaps
return to them at a later point.

[[https://en.wikipedia.org/wiki/Microscopy][Microscopy]] is the technical name for the observation work done with
the microscope. Because neurons are so small~--- some 4 to 100 microns
in size~--- only certain types of microscopes are suitable to perform
this of kind work. To make matters worse, the sub-structures inside
the neuron are really what we want to know about and these can be
quite small. For example, a [[https://en.wikipedia.org/wiki/Dendritic_spine][dentritic spine]]~--- the small protrusions
that come out of the dendrites~--- can be as small as 500 nanometres.
The lipid bylayer itself is only 2 or 3 nanometres thick, so you can
imagine how tiny ion channels and ion pumps are. Yet we must know
about these structures in order to improve our models.

#+CAPTION: Source: [[http://www.pnas.org/content/106/39/16877.abstract][Reversal of long-term dendritic spine alterations in Alzheimer disease models]]
#+attr_html: :width 300px :height 300px
http://www.pnas.org/content/106/39/16877/F1.large.jpg

The tool of choice is the [[https://en.wikipedia.org/wiki/Electron_microscope][Electron Microscope (EM)]]. This crazy critter
can provide insane levels of magnification by using a beam of
electrons instead of visible light~--- as done by the more
conventional [[https://en.wikipedia.org/wiki/Optical_microscope][Optical Microscopes]]. In particular, the [[https://en.wikipedia.org/wiki/Scanning_electron_microscope][Scanning Electron
Microscope]] (SEM) performs a scan of the object under study, and has a
resolution higher than 1 nanometre. In addition, there are also
[[https://en.wikipedia.org/wiki/Confocal_microscopy][Confocal Microscopes]] which use a technique patented by [[https://en.wikipedia.org/wiki/Marvin_Minsky][Marvin
Minsky]]~--- yes, he of Computer Science and AI fame~--- which improves
resolution and contrast. It seems the same principles are also applied
to EM, creating [[https://en.wikipedia.org/wiki/Scanning_confocal_electron_microscopy][SCEM microscopes]]. Whatever the details, the fact is
that the imagery that results from all of these advances is truly
haunting. Take this image of a neuron:

#+CAPTION: [[http://ucsdnews.ucsd.edu/pressrelease/new_reprogramming_method_makes_better_stem_cells][Source: New Reprogramming Method Makes Better Stem Cells]]
#+attr_html: :width 300px :height 300px
http://ucsdnews.ucsd.edu/news_uploads/2014_06_26_human_ipsc_derived_neuron_deerinck.jpg

Technically, these pictures are called [[https://en.wikipedia.org/wiki/Micrograph][micrographs]]. As you can see,
they provide a great visual description of the topology of the object
we are trying to study. You may notice a slight coloration of the cell
in that picture. This is most likely due to the fact that the people
doing the analysis [[https://en.wikipedia.org/wiki/Staining][stain]] the neuron to make it easier to image. Its
worth noting that the entire process, including staining and taking
the pictures, is still highly manual and requires a lot of skill, most
likely done by an expert human neuroanatomist.

Now, in practice~--- at least as far as I have seen, which is not very
far at all, to be fair~--- 2D images are preferred by researchers to
the nice, Public Relations friendly pictures like the one above; these
seem to be more useful for the cover of magazines. The working
micrographs look a bit more like this:

#+CAPTION: Source: [[http://figshare.com/articles/Segmented_anisotropic_ssTEM_dataset_of_neural_tissue/856713][Segmented anisotropic ssTEM dataset of neural tissue]]
#+attr_html: :width 300px :height 300px
http://previews.figshare.com/1288336/preview_1288336.jpg

This is one picture of a /stack/ of images. Normally, the stack covers
different slices of the same tissue and great effort is done to ensure
consistency amongst all images. For example, say you start off with a
400 micrometre slice of a rat's brain~--- I did warn you we were in
the physical world now, so no squirming!~--- and then thinly slice
thinly into sections only a few nanometres thick, like say 60
nanometres. You then create micrographs for each of these (or portions
of them, presumably). The trick is to ensure there is some kind of
visual continuity between images so that you can recreate a 3D model
from these 2D slices. This means for instance that if you are trying
to figure connectivity out, you need some way to relate a dendrite to
it's soma and say to the axon of the neuron it connects to. It would
be no good if the pictures miss this information out as you will not
be able to recreate the connectivity faithfully.

Images in a stack are normally stored using traditional formats such
as [[https://en.wikipedia.org/wiki/Tagged_Image_File_Format][TIFF]]. You can see an example of the raw images in a stack [[https://github.com/unidesigner/groundtruth-drosophila-vnc/tree/master/stack2/raw][here]];
they are part of the challenge mentioned above. On this topic, its
probably time we mention the [[https://www.openmicroscopy.org/site][Open Microscopy Environment]] (OME). The
microscopy world is dominated by hardware and as such its the perfect
environment for corporations, their proprietary formats and expensive
software packages. The OME guys are trying to buck the trend by
creating a suite of open source tools and protocols, and by looking at
some of [[http://help.openmicroscopy.org/viewing-data.html#screen][their stuff]], they seem to be doing alright.

* What To Do Once You Got the Images

But back to the task at hand. Once you have micrographs, the next
logical step is to try to figure out what's what: which objects are in
the picture. This is called segmentation and labelling, presumably
because you are breaking the one big monolithic picture into discrete
objects and giving them names. Historically, segmentation has been
done manually, but its a painful, slow and error-prone process. Due to
this, there is a lot of interest in automation, and it has recently
become feasible to do so~--- what with the abundance of cheap
computing resources as well as the advent of "useful" [[https://en.wikipedia.org/wiki/Machine_learning][machine learning]]
(rather than the theoretical variety). Cracking this puzzle is gaining
popularity amongst the programming nerds as you can see by the
popularity of challenges such as this one: [[http://fiji.sc/Segmentation_of_neuronal_structures_in_EM_stacks_challenge_-_ISBI_2012][Segmentation of neuronal
structures in EM stacks challenge - ISBI 2012]]

An activity that naturally follows on from segmentation and labelling
is [[https://en.wikipedia.org/wiki/Neuronal_tracing][reconstruction]]. The objective of reconstruction is to try to
reconstruct morphology given the images in the stack. It could involve
inferring the missing bits of information or any other kind of
analysis which transforms the set of discrete objects spotted by
segmentation into something looking more like a bunch of connected
neurons. Unfortunately for the lovers of Free Software, reconstruction
tends to be done using proprietary tools such as [[http://www.mbfbioscience.com/neurolucida][NeuroLucida]]. On the
plus side, NeuroLucida does output slightly more open formats such as
NeuroLucida XML, which appears to have been [[https://code.google.com/p/ontomorphtab/source/browse/trunk/OntoMorph2/etc/neurolucida-xml/neurolucida-xml.xsd?r%3D335][reverse-engineered]].

For our purposes, it is important to obtain the reconstructed models
in an accessible format because they are in effect the input to two
very important activities: morphometry and the simulations we
mentioned before. Morphometry is basically the analysis

* Stuff

Segmentation and Tracking of 3D Neuron Microscopy Images Using a
PDE Based Method and Connected Component Labeling algorithm
ftp://ftp.math.ucla.edu/pub/camreport/cam08-03.pdf


http://web.cs.ucla.edu/~dt/papers/tmi94/tmi94.pdf
